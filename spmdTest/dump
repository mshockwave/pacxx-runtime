
### Whole-Function Vectorization of function '_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE' (width 8, all analyses ENABLED)...

define ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  %0 = addrspacecast float addrspace(1)* %args to float*
  %1 = addrspacecast float addrspace(1)* %args1 to float*
  %2 = addrspacecast float addrspace(1)* %args2 to float*
  br label %_Z13get_global_idj.exit

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4
  %6 = mul i32 %3, %4
  %7 = add i32 %6, %5
  %8 = mul nsw i32 %7, 1024
  br label %.lr.ph.i

.lr.ph.i:                                         ; preds = %_Z13get_global_idj.exit, %.lr.ph.i
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i ]
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i ]
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4
  %12 = mul i32 %9, %10
  %13 = add i32 %12, %11
  %14 = add nsw i32 %i.0.i, %8
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds float, float* %0, i64 %15
  %17 = mul nsw i32 %i.0.i, 1024
  %18 = add nsw i32 %17, %13
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds float, float* %1, i64 %19
  %21 = load float, float* %16, align 4
  %22 = load float, float* %20, align 4
  %23 = fmul float %21, %22
  %24 = fadd float %val.0.i, %23
  %25 = add nuw nsw i32 %i.0.i, 1
  %26 = icmp slt i32 %25, 1024
  br i1 %26, label %.lr.ph.i, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit"

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  %.lcssa1 = phi float [ %24, %.lr.ph.i ]
  %.lcssa = phi i32 [ %13, %.lr.ph.i ]
  %27 = add nsw i32 %8, %.lcssa
  %28 = sext i32 %27 to i64
  %29 = getelementptr inbounds float, float* %2, i64 %28
  store float %.lcssa1, float* %29, align 4
  ret void
}

define internal ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  %0 = addrspacecast float addrspace(1)* %args to float*
  %1 = addrspacecast float addrspace(1)* %args1 to float*
  %2 = addrspacecast float addrspace(1)* %args2 to float*
  br label %_Z13get_global_idj.exit

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4
  %6 = mul i32 %3, %4
  %7 = add i32 %6, %5
  %8 = mul nsw i32 %7, 1024
  br label %.lr.ph.i

.lr.ph.i:                                         ; preds = %.lr.ph.i, %_Z13get_global_idj.exit
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i ]
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i ]
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4
  %12 = mul i32 %9, %10
  %13 = add i32 %12, %11
  %14 = add nsw i32 %i.0.i, %8
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds float, float* %0, i64 %15
  %17 = mul nsw i32 %i.0.i, 1024
  %18 = add nsw i32 %17, %13
  %19 = sext i32 %18 to i64
  %20 = getelementptr inbounds float, float* %1, i64 %19
  %21 = load float, float* %16, align 4
  %22 = load float, float* %20, align 4
  %23 = fmul float %21, %22
  %24 = fadd float %val.0.i, %23
  %25 = add nuw nsw i32 %i.0.i, 1
  %26 = icmp slt i32 %25, 1024
  br i1 %26, label %.lr.ph.i, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit"

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  %.lcssa1 = phi float [ %24, %.lr.ph.i ]
  %.lcssa = phi i32 [ %13, %.lr.ph.i ]
  %27 = add nsw i32 %8, %.lcssa
  %28 = sext i32 %27 to i64
  %29 = getelementptr inbounds float, float* %2, i64 %28
  store float %.lcssa1, float* %29, align 4
  ret void
}

declare void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8, float addrspace(1)*, float addrspace(1)*, float addrspace(1)*, i32)
findSCC(addrspacecast(0))
findSCC(_Z13get_global_idj.exit(1))
findSCC(.lr.ph.i(2))
findSCC(.lr.ph.i..lr.ph.i_crit_edge(3))
  successor .lr.ph.i is in stack -> in current SCC.
findSCC(_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit(4))
  new SCC:  *_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit
  new SCC:  *.lr.ph.i .lr.ph.i..lr.ph.i_crit_edge
  new SCC:  *_Z13get_global_idj.exit
  new SCC:  addrspacecast

SCCs at level 0:
 *.lr.ph.i .lr.ph.i..lr.ph.i_crit_edge

ignored edge for next iteration: '.lr.ph.i..lr.ph.i_crit_edge' -> '.lr.ph.i
findSCC(.lr.ph.i(0))
findSCC(.lr.ph.i..lr.ph.i_crit_edge(1))
  new SCC:  *.lr.ph.i..lr.ph.i_crit_edge
findSCC(_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit(2))
  new SCC:  *_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit
  new SCC:  *.lr.ph.i

SCCs at level 1:

SCCs:
*   *.lr.ph.i .lr.ph.i..lr.ph.i_crit_edge

ValueInfoMap:

  marking value:  as op_uniform...
  marking value:  as res_uniform...
  marking value:  as op_uniform...
  marking value:  as res_uniform...
  marking value:  as op_uniform...
  marking value:  as res_uniform...
  marking value:  as op_uniform...
  marking value:  as res_uniform...
  marking value:  as op_uniform...
  marking value:  as res_uniform...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value: .lcssa as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value:  as op_varying...
  marking value:  as res_vector...
  marking value: .lcssa1 as res_vector...
    previously marked as OP_VARYING - ignored!
  marking value: val.0.i as res_vector...
    previously marked as OP_VARYING - ignored!
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value:  as op_uniform...
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value: val.0.i as op_uniform...
  marking value: i.0.i as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!
  marking value: .lcssa1 as op_uniform...
  marking value: .lcssa as op_uniform...
  marking value:  as op_uniform...
    previously marked as op_uniform - ignored!

Marking divergent loops...

  marking value: .lr.ph.i as loop_non_divergent...

Marking blocks that are always executed by all threads..[VA] Graph with 1 nodes to small for compaction
[VA] Graph with 1 nodes to small for compaction
.

  marking value: addrspacecast as always_by_all...
  marking value: _Z13get_global_idj.exit as always_by_all...
  marking value: .lr.ph.i as always_by_all...
  marking value: _ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit as always_by_all...
  marking value: .lr.ph.i..lr.ph.i_crit_edge as always_by_all_or_none...

Marking divergent blocks...


isDivergent(addrspacecast)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: addrspacecast as non_divergent...

isDivergent(_Z13get_global_idj.exit)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: _Z13get_global_idj.exit as non_divergent...

isDivergent(.lr.ph.i)
  no pair of incoming edges with disjoint paths - NON_DIVERGENT!
  marking value: .lr.ph.i as non_divergent...

isDivergent(.lr.ph.i..lr.ph.i_crit_edge)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: .lr.ph.i..lr.ph.i_crit_edge as non_divergent...

isDivergent(_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: _ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit as non_divergent...

Updating phis with divergence information...


Updating operations with possible side effects...


Updating alloca uniform/varying information...


Updating values that are live across loop boundaries...


Marking divergent loops...

  marking value: .lr.ph.i as loop_non_divergent...
    previously marked as loop_non_divergent - ignored!

Marking blocks that are always executed by all threads...

  marking value: addrspacecast as always_by_all...
    previously marked as always_by_all - ignored!
  marking value: _Z13get_global_idj.exit as always_by_all...
    previously marked as always_by_all - ignored!
  marking value: .lr.ph.i as always_by_all...
    previously marked as always_by_all - ignored!
  marking value: _ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit as always_by_all...
    previously marked as always_by_all - ignored!
  marking value: .lr.ph.i..lr.ph.i_crit_edge as always_by_all_or_none...
    previously marked as always_by_all_or_none - ignored!

Marking divergent blocks...


isDivergent(addrspacecast)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: addrspacecast as non_divergent...
    previously marked as non_divergent - ignored!

isDivergent(_Z13get_global_idj.exit)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: _Z13get_global_idj.exit as non_divergent...
    previously marked as non_divergent - ignored!

isDivergent(.lr.ph.i)
  no pair of incoming edges with disjoint paths - NON_DIVERGENT!
  marking value: .lr.ph.i as non_divergent...
    previously marked as non_divergent - ignored!

isDivergent(.lr.ph.i..lr.ph.i_crit_edge)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: .lr.ph.i..lr.ph.i_crit_edge as non_divergent...
    previously marked as non_divergent - ignored!

isDivergent(_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit)
  has less than two incoming edges - NON_DIVERGENT!
  marking value: _ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit as non_divergent...
    previously marked as non_divergent - ignored!

Updating phis with divergence information...


Updating operations with possible side effects...


Updating alloca uniform/varying information...


Updating values that are live across loop boundaries...


Marking mandatory/optional blocks...


isMandatory(addrspacecast)
  marking value: addrspacecast as optional...

isMandatory(_Z13get_global_idj.exit)
  marking value: _Z13get_global_idj.exit as optional...

isMandatory(.lr.ph.i)
  marking value: .lr.ph.i as optional...

isMandatory(.lr.ph.i..lr.ph.i_crit_edge)
  marking value: .lr.ph.i..lr.ph.i_crit_edge as optional...

isMandatory(_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit)
  reachable edges do not fulfill loop exit criterion - no divergence (4)!
  marking value: _ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit as optional...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
    previously marked as res_uniform - ignored!
  marking value:  as res_uniform...
    previously marked as res_uniform - ignored!
  marking value:  as res_uniform...
    previously marked as res_uniform - ignored!
  marking value:  as res_uniform...
    previously marked as res_uniform - ignored!
  marking value:  as res_uniform...
    previously marked as res_uniform - ignored!
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value: i.0.i as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...
  marking value:  as res_uniform...

marking index/alignment info of arguments...
marked UNIFORM argument: i8 %callable.coerce as INDEX_SAME / ALIGNED_FALSE!
marked UNIFORM argument: float addrspace(1)* %args as INDEX_SAME / ALIGNED_TRUE!
marked UNIFORM argument: float addrspace(1)* %args1 as INDEX_SAME / ALIGNED_TRUE!
marked UNIFORM argument: float addrspace(1)* %args2 as INDEX_SAME / ALIGNED_TRUE!
marked UNIFORM argument: i32 %args3 as INDEX_SAME / ALIGNED_FALSE!

workSet:
 *   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
 *   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
 *   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
 *   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_varying !25, !res_vector !25
 *   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_varying !25, !res_vector !25
 *   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_varying !25, !res_vector !25
 *   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25
 *   store float %.lcssa1, float* %29, align 4, !op_varying !25

marking instructions...
markIndexAlignValueAndOps(1):   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(4):   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
  marked value:   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(4):   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
  marked value:   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(4):   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25
  marked value:   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(4):   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_varying !25, !res_vector !25
  marked instruction as INDEX_RANDOM / ALIGN_FALSE!
  marked value:   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(1):   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(4):   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_varying !25, !res_vector !25
  marked instruction as INDEX_RANDOM / ALIGN_FALSE!
  marked value:   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(1):   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(4):   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_varying !25, !res_vector !25
  marked instruction as INDEX_RANDOM / ALIGN_FALSE!
  marked value:   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(1):   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1): i32 0
markIndexAlignValueAndOps(2):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25
  marked loop phi:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
markIndexAlignValueAndOps(1):   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
  already marked as same / aligned - ignored!
markIndexAlignValueAndOps(1): i32 1
markIndexAlignValueAndOps(4):   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25
  marked value:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(3):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
  updated loop phi:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  already marked as same / unaligned - ignored!
markIndexAlignValueAndOps(1): i32 1
markIndexAlignValueAndOps(4):   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  marked value:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(3):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  updated loop phi:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1): i32 1
markIndexAlignValueAndOps(4):   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  marked value:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1): i32 1024
markIndexAlignValueAndOps(4):   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25
  marked value:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(4):   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25
  has void type - ignored!
markIndexAlignValueAndOps(1):   store float %.lcssa1, float* %29, align 4, !op_varying !25
markIndexAlignValueAndOps(1):   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25
markIndexAlignValueAndOps(1):   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25
markIndexAlignValueAndOps(1): float 0.000000e+00
markIndexAlignValueAndOps(2):   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25
  marked loop phi:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !same !25, !unaligned !25
  already marked as same / unaligned - ignored!
markIndexAlignValueAndOps(1):   %23 = fmul float %21, %22, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %21 = load float, float* %16, align 4, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1): float addrspace(1)* %args
  already marked as same / aligned - ignored!
markIndexAlignValueAndOps(4):   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25
  marked value:   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  already marked as same / unaligned - ignored!
markIndexAlignValueAndOps(1):   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %7 = add i32 %6, %5, !global_id_y !25, !op_uniform !25, !res_uniform !25, !same !25
  already marked as same /  - ignored!
markIndexAlignValueAndOps(1): i32 1024
markIndexAlignValueAndOps(4):   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25
  marked value:   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
markIndexAlignValueAndOps(4):   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25
  marked value:   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(4):   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25
  marked value:   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(4):   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25
Analyzing   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25
Base flat : 1
Target flat : 1    float*
      isSOA : 0
ii[0] same
ii[1] same
-> Uniform GEP

  marked value:   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(4):   %21 = load float, float* %16, align 4, !op_uniform !25, !res_uniform !25
  marked value:   %21 = load float, float* %16, align 4, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %22 = load float, float* %20, align 4, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1): float addrspace(1)* %args1
  already marked as same / aligned - ignored!
markIndexAlignValueAndOps(4):   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25
  marked value:   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %19 = sext i32 %18 to i64, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %18 = add nsw i32 %17, %13, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1):   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  already marked as same / unaligned - ignored!
markIndexAlignValueAndOps(1): i32 1024
markIndexAlignValueAndOps(4):   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25
  marked value:   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
markIndexAlignValueAndOps(1):   %13 = add i32 %12, %11, !global_id_x !25, !op_varying !25, !res_vector !25, !consecutive !25
  already marked as consecutive /  - ignored!
markIndexAlignValueAndOps(4):   %18 = add nsw i32 %17, %13, !op_varying !25, !res_vector !25
  marked value:   %18 = add nsw i32 %17, %13, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   %19 = sext i32 %18 to i64, !op_varying !25, !res_vector !25
  marked value:   %19 = sext i32 %18 to i64, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25
Analyzing   %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25
Base flat : 1
Target flat : 1    float*
      isSOA : 0
ii[0] same
ii[1] consecutive
-> Consecutive flat GEP

  marked value:   %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   %22 = load float, float* %20, align 4, !op_varying !25, !res_vector !25
  marked instruction as INDEX_RANDOM / ALIGN_FALSE!
  marked value:   %22 = load float, float* %20, align 4, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(4):   %23 = fmul float %21, %22, !op_varying !25, !res_vector !25
  marked value:   %23 = fmul float %21, %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(4):   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25
  marked value:   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(3):   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !same !25, !unaligned !25
  updated loop phi:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(1):   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
  already marked as random / unaligned - ignored!
markIndexAlignValueAndOps(3):   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
  updated loop phi:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(1):   %23 = fmul float %21, %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
  already marked as random / unaligned - ignored!
markIndexAlignValueAndOps(4):   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
  marked value:   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(4):   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25
  marked value:   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
markIndexAlignValueAndOps(1):   %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25
markIndexAlignValueAndOps(1): float addrspace(1)* %args2
  already marked as same / aligned - ignored!
markIndexAlignValueAndOps(4):   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25
  marked value:   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
markIndexAlignValueAndOps(1):   %28 = sext i32 %27 to i64, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %27 = add nsw i32 %8, %.lcssa, !op_varying !25, !res_vector !25
markIndexAlignValueAndOps(1):   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
  already marked as same / aligned - ignored!
markIndexAlignValueAndOps(1):   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25
markIndexAlignValueAndOps(1):   %13 = add i32 %12, %11, !global_id_x !25, !op_varying !25, !res_vector !25, !consecutive !25
  already marked as consecutive /  - ignored!
markIndexAlignValueAndOps(4):   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25
  marked value:   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   %27 = add nsw i32 %8, %.lcssa, !op_varying !25, !res_vector !25
  marked value:   %27 = add nsw i32 %8, %.lcssa, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   %28 = sext i32 %27 to i64, !op_varying !25, !res_vector !25
  marked value:   %28 = sext i32 %27 to i64, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25
Analyzing   %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25
Base flat : 1
Target flat : 1    float*
      isSOA : 0
ii[0] same
ii[1] consecutive
-> Consecutive flat GEP

  marked value:   %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
markIndexAlignValueAndOps(4):   store float %.lcssa1, float* %29, align 4, !op_varying !25
  has void type - ignored!

Marking instructions that have to be split and executed sequentially instead of vectorized...
testing if instruction has to be split:   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   br label %_Z13get_global_idj.exit, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br label %_Z13get_global_idj.exit, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %6 = mul i32 %3, %4, !idy !25, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   %6 = mul i32 %3, %4, !idy !25, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %7 = add i32 %6, %5, !global_id_y !25, !op_uniform !25, !res_uniform !25, !same !25...
  is OP_UNIFORM - ignored:   %7 = add i32 %6, %5, !global_id_y !25, !op_uniform !25, !res_uniform !25, !same !25
testing if instruction has to be split:   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25...
  is OP_UNIFORM - ignored:   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
testing if instruction has to be split:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
  marking value:  as op_sequential...
testing if instruction has to be split:   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
  marking value:  as op_sequential...
testing if instruction has to be split:   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
  marking value:  as op_sequential...
testing if instruction has to be split:   %12 = mul i32 %9, %10, !idx !25, !op_varying !25, !res_vector !25...
testing if instruction has to be split:   %13 = add i32 %12, %11, !global_id_x !25, !op_varying !25, !res_vector !25, !consecutive !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25...
  is OP_UNIFORM - ignored:   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
testing if instruction has to be split:   %18 = add nsw i32 %17, %13, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %19 = sext i32 %18 to i64, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %21 = load float, float* %16, align 4, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored!
testing if instruction has to be split:   %22 = load float, float* %20, align 4, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
    load can be VECTORIZED!
testing if instruction has to be split:   %23 = fmul float %21, %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
testing if instruction has to be split:   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
testing if instruction has to be split:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25
testing if instruction has to be split:   %27 = add nsw i32 %8, %.lcssa, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %28 = sext i32 %27 to i64, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   store float %.lcssa1, float* %29, align 4, !op_varying !25...
    store can be VECTORIZED!
testing if instruction has to be split:   ret void, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   ret void, !op_uniform !25, !res_uniform !25

Marking instructions that have to be split and executed sequentially instead of vectorized...
testing if instruction has to be split:   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   br label %_Z13get_global_idj.exit, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br label %_Z13get_global_idj.exit, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !25, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %6 = mul i32 %3, %4, !idy !25, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   %6 = mul i32 %3, %4, !idy !25, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %7 = add i32 %6, %5, !global_id_y !25, !op_uniform !25, !res_uniform !25, !same !25...
  is OP_UNIFORM - ignored:   %7 = add i32 %6, %5, !global_id_y !25, !op_uniform !25, !res_uniform !25, !same !25
testing if instruction has to be split:   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25...
  is OP_UNIFORM - ignored:   %8 = mul nsw i32 %7, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
testing if instruction has to be split:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_sequential !25, !res_vector !25, !random !25, !unaligned !25...
  has been marked as OP_SEQUENTIAL/_GUARDED already - ignored:   %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !25, !op_sequential !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_sequential !25, !res_vector !25, !random !25, !unaligned !25...
  has been marked as OP_SEQUENTIAL/_GUARDED already - ignored:   %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !25, !op_sequential !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_sequential !25, !res_vector !25, !random !25, !unaligned !25...
  has been marked as OP_SEQUENTIAL/_GUARDED already - ignored:   %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !25, !op_sequential !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %12 = mul i32 %9, %10, !idx !25, !op_varying !25, !res_vector !25...
testing if instruction has to be split:   %13 = add i32 %12, %11, !global_id_x !25, !op_varying !25, !res_vector !25, !consecutive !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %14 = add nsw i32 %i.0.i, %8, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %15 = sext i32 %14 to i64, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25...
  is OP_UNIFORM - ignored:   %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !25, !res_uniform !25, !same !25, !aligned !25
testing if instruction has to be split:   %18 = add nsw i32 %17, %13, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %19 = sext i32 %18 to i64, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %21 = load float, float* %16, align 4, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored!
testing if instruction has to be split:   %22 = load float, float* %20, align 4, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
    load can be VECTORIZED!
testing if instruction has to be split:   %23 = fmul float %21, %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
testing if instruction has to be split:   %24 = fadd float %val.0.i, %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25...
testing if instruction has to be split:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
testing if instruction has to be split:   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   br label %.lr.ph.i, !op_uniform !25, !res_uniform !25
testing if instruction has to be split:   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25
testing if instruction has to be split:   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is OP_UNIFORM - ignored:   %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25
testing if instruction has to be split:   %27 = add nsw i32 %8, %.lcssa, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %28 = sext i32 %27 to i64, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25...
  is INDEX_CONSECUTIVE - ignored!
testing if instruction has to be split:   store float %.lcssa1, float* %29, align 4, !op_varying !25...
    store can be VECTORIZED!
testing if instruction has to be split:   ret void, !op_uniform !25, !res_uniform !25...
  is OP_UNIFORM - ignored:   ret void, !op_uniform !25, !res_uniform !25

Marking mask operations...
masking instruction  marking value:  as mask...

define internal ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit, !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

.lr.ph.i:                                         ; preds = %.lr.ph.i..lr.ph.i_crit_edge, %_Z13get_global_idj.exit
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i, %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i, %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge:                      ; preds = %.lr.ph.i
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %.lcssa, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %.lcssa1, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}

define internal ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit, !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

.lr.ph.i:                                         ; preds = %.lr.ph.i..lr.ph.i_crit_edge, %_Z13get_global_idj.exit
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i, %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i, %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge:                      ; preds = %.lr.ph.i
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %.lcssa, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %.lcssa1, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}


after analysisVariant regions found:

#########################################################
## MASK ANALYSIS
#########################################################

generating mask information for block 'addrspacecast'... 
  entryMask (1): 0: i1 true

  createExitMasks(addrspacecast)
  exitMask  (1): 0: i1 true

generated mask information for block 'addrspacecast':
BlockMaskInfo for block 'addrspacecast':
  entry mask : 0: i1 true

  exit mask 0: 0: i1 true


generating mask information for block '_Z13get_global_idj.exit'... 
  entryMask (2): 1: i1 true

  createExitMasks(_Z13get_global_idj.exit)
  exitMask  (1): 1: i1 true

generated mask information for block '_Z13get_global_idj.exit':
BlockMaskInfo for block '_Z13get_global_idj.exit':
  entry mask : 1: i1 true

  exit mask 0: 1: i1 true


generating mask information for block '.lr.ph.i'... 
  entryMask (2): 2: i1 true

  createExitMasks(.lr.ph.i)
  condition  (2): 3:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25, !mask !25

  true mask  (2): 2: i1 true

  false mask (2): 4: i1 false

  exitMask  (2): 5: SELECT( 3, 2, 4 )
  condition  (2): 6:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25, !mask !25

  true mask  (2): 7: i1 false

  false mask (2): 2: i1 true

  exitMask  (2): 8: SELECT( 6, 7, 2 )
generated mask information for block '.lr.ph.i':
BlockMaskInfo for block '.lr.ph.i':
  entry mask : 2: i1 true

  exit mask 0: 5: SELECT( 3, 2, 4 )
  exit mask 1: 8: SELECT( 6, 7, 2 )

generating mask information for block '.lr.ph.i..lr.ph.i_crit_edge'... 
  entryMask (2): 9: i1 true

  createExitMasks(.lr.ph.i..lr.ph.i_crit_edge)
  exitMask  (1): 9: i1 true

generated mask information for block '.lr.ph.i..lr.ph.i_crit_edge':
BlockMaskInfo for block '.lr.ph.i..lr.ph.i_crit_edge':
  entry mask : 9: i1 true

  exit mask 0: 9: i1 true


generating mask information for block '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'... 
  entryMask (2): 10: i1 true

  createExitMasks(_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit)
generated mask information for block '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit':
BlockMaskInfo for block '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit':
  entry mask : 10: i1 true

Non-divergent sub-loop ignored: .lr.ph.i
Masks:
0: i1 true

1: i1 true

2: i1 true

3:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25, !mask !25

4: i1 false

5: SELECT( 3, 2, 4 )
6:   %26 = icmp slt i32 %25, 1024, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25, !mask !25

7: i1 false

8: SELECT( 6, 7, 2 )
9: i1 true

10: i1 true


Block Mask Info:
BlockMaskInfo for block '_Z13get_global_idj.exit':
  entry mask : 1: i1 true

  exit mask 0: 1: i1 true

BlockMaskInfo for block '.lr.ph.i..lr.ph.i_crit_edge':
  entry mask : 9: i1 true

  exit mask 0: 9: i1 true

BlockMaskInfo for block '.lr.ph.i':
  entry mask : 2: i1 true

  exit mask 0: 5: SELECT( 3, 2, 4 )
  exit mask 1: 8: SELECT( 6, 7, 2 )
BlockMaskInfo for block 'addrspacecast':
  entry mask : 0: i1 true

  exit mask 0: 0: i1 true

BlockMaskInfo for block '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit':
  entry mask : 10: i1 true


Loop Mask Info:

Loop Exit Mask Info:


#########################################################
## MASK GENERATION
#########################################################

define internal ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit, !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

.lr.ph.i:                                         ; preds = %.lr.ph.i..lr.ph.i_crit_edge, %_Z13get_global_idj.exit
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i, %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i, %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge:                      ; preds = %.lr.ph.i
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %.lcssa, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %.lcssa1, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}
analyzing function for values live across loop boundaries

collecting all values that are live across loop boundaries...

Values live across loop boundaries:

loop live value analysis finished.

#########################################################
## SELECT GENERATION
#########################################################

Generating selects for loops of function _ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp... 
  Ignored non-divergent loop: .lr.ph.i

Generation of loop-selects finished!

define internal ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit, !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

.lr.ph.i:                                         ; preds = %.lr.ph.i..lr.ph.i_crit_edge, %_Z13get_global_idj.exit
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i, %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i, %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge:                      ; preds = %.lr.ph.i
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  %.lcssa1 = phi float [ %24, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %.lcssa = phi i32 [ %13, %.lr.ph.i ], !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %.lcssa, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %.lcssa1, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}

#########################################################
## CFG LINEARIZATION
#########################################################

dc blocks:

Clusters:

determineNewEdges('addrspacecast')
determineNewEdges('_Z13get_global_idj.exit')
determineNewEdges('.lr.ph.i')
determineNewEdges('.lr.ph.i..lr.ph.i_crit_edge')
determineNewEdges('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit')

Linearize info:
Block '_Z13get_global_idj.exit':
  old successor : '.lr.ph.i'
  edge type     : 0
  new successors: '.lr.ph.i'
  rewire-causing:
Block '.lr.ph.i..lr.ph.i_crit_edge':
  old successor : '.lr.ph.i'
  edge type     : 0
  new successors: '.lr.ph.i'
  rewire-causing:
Block '.lr.ph.i':
  old successor : '.lr.ph.i..lr.ph.i_crit_edge'
  edge type     : 0
  new successors: '.lr.ph.i..lr.ph.i_crit_edge'
  rewire-causing:
  old successor : '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'
  edge type     : 0
  new successors: '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'
  rewire-causing:
Block 'addrspacecast':
  old successor : '_Z13get_global_idj.exit'
  edge type     : 0
  new successors: '_Z13get_global_idj.exit'
  rewire-causing:

reg2mem:   %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
  block        ('addrspacecast')
  alloca       ('addrspacecast'):   %.reg2mem = alloca float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  new store    ('addrspacecast'):   store float* %0, float** %.reg2mem
  new reload   ('.lr.ph.i'):   %.reload = load float*, float** %.reg2mem

reg2mem:   %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block        ('addrspacecast')
  alloca       ('addrspacecast'):   %.reg2mem1 = alloca float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  new store    ('addrspacecast'):   store float* %1, float** %.reg2mem1
  new reload   ('.lr.ph.i'):   %.reload2 = load float*, float** %.reg2mem1

reg2mem:   %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block        ('addrspacecast')
  alloca       ('addrspacecast'):   %.reg2mem3 = alloca float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  new store    ('addrspacecast'):   store float* %2, float** %.reg2mem3
  new reload   ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.reload4 = load float*, float** %.reg2mem3

reg2mem:   %8 = mul nsw i32 %7, 1024, !op_uniform !19, !res_uniform !19, !same !19, !aligned !19
  block        ('_Z13get_global_idj.exit')
  alloca       ('addrspacecast'):   %.reg2mem5 = alloca i32, !op_uniform !19, !res_uniform !19, !same !19, !aligned !19
  new store    ('_Z13get_global_idj.exit'):   store i32 %8, i32* %.reg2mem5
  new reload   ('.lr.ph.i'):   %.reload7 = load i32, i32* %.reg2mem5
  new reload   ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.reload6 = load i32, i32* %.reg2mem5

reg2mem:   %13 = add i32 %12, %11, !global_id_x !19, !op_varying !19, !res_vector !19, !consecutive !19
  block        ('.lr.ph.i')
  alloca       ('addrspacecast'):   %.reg2mem8 = alloca i32, !op_varying !19, !res_vector !19, !consecutive !19
  new store    ('.lr.ph.i'):   store i32 %13, i32* %.reg2mem8
  new reload   ('.lr.ph.i'):   %.reload10 = load i32, i32* %.reg2mem8
  new reload   ('.lr.ph.i'):   %.reload9 = load i32, i32* %.reg2mem8
  generated undef store: .lr.ph.i

reg2mem:   %24 = fadd float %val.0.i, %23, !op_varying !19, !res_vector !19, !random !19, !unaligned !19
  block        ('.lr.ph.i')
  alloca       ('addrspacecast'):   %.reg2mem11 = alloca float, !op_varying !19, !res_vector !19, !random !19, !unaligned !19
  new store    ('.lr.ph.i'):   store float %24, float* %.reg2mem11
  new reload   ('.lr.ph.i..lr.ph.i_crit_edge'):   %.reload13 = load float, float* %.reg2mem11
  new reload   ('.lr.ph.i'):   %.reload12 = load float, float* %.reg2mem11

reg2mem:   %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block        ('.lr.ph.i')
  alloca       ('addrspacecast'):   %.reg2mem14 = alloca i32, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  new store    ('.lr.ph.i'):   store i32 %25, i32* %.reg2mem14
  new reload   ('.lr.ph.i..lr.ph.i_crit_edge'):   %.reload16 = load i32, i32* %.reg2mem14
  new reload   ('.lr.ph.i'):   %.reload15 = load i32, i32* %.reg2mem14

phi2mem: 0x36b3388  %.lcssa1 = phi float [ %.reload12, %.lr.ph.i ], !op_uniform !19, !res_vector !19, !random !19, !unaligned !19
  block        ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit')
  addr         ('0x36b3388')
  alloca       ('addrspacecast'):   %.lcssa1.reg2mem = alloca float, !op_uniform !19, !res_vector !19, !random !19, !unaligned !19
  phi reload   ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.lcssa1.reload = load float, float* %.lcssa1.reg2mem
  phi store    ('.lr.ph.i'):   store float %.reload12, float* %.lcssa1.reg2mem

phi2mem: 0x36b3438  %.lcssa = phi i32 [ %.reload9, %.lr.ph.i ], !op_uniform !19, !res_vector !19, !consecutive !19, !unaligned !19
  block        ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit')
  addr         ('0x36b3438')
  alloca       ('addrspacecast'):   %.lcssa.reg2mem = alloca i32, !op_uniform !19, !res_vector !19, !consecutive !19, !unaligned !19
  phi reload   ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.lcssa.reload = load i32, i32* %.lcssa.reg2mem
  phi store    ('.lr.ph.i'):   store i32 %.reload9, i32* %.lcssa.reg2mem

rewiring edges of block 'addrspacecast'...
  successor '_Z13get_global_idj.exit'

rewiring edges of block '_Z13get_global_idj.exit'...
  successor '.lr.ph.i'

rewiring edges of block '.lr.ph.i'...
  successor '.lr.ph.i..lr.ph.i_crit_edge'
  successor '_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'

rewiring edges of block '.lr.ph.i..lr.ph.i_crit_edge'...
  successor '.lr.ph.i'

Repairing SSA form after CFG linearization...

mem2reg:   %.reg2mem = alloca float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block   ('addrspacecast')
  store   ('addrspacecast'):   store float* %0, float** %.reg2mem
  reload  ('.lr.ph.i'):   %.reload = load float*, float** %.reg2mem

mem2reg:   %.reg2mem1 = alloca float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block   ('addrspacecast')
  store   ('addrspacecast'):   store float* %1, float** %.reg2mem1
  reload  ('.lr.ph.i'):   %.reload2 = load float*, float** %.reg2mem1

mem2reg:   %.reg2mem3 = alloca float*, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block   ('addrspacecast')
  store   ('addrspacecast'):   store float* %2, float** %.reg2mem3
  reload  ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.reload4 = load float*, float** %.reg2mem3

mem2reg:   %.reg2mem5 = alloca i32, !op_uniform !19, !res_uniform !19, !same !19, !aligned !19
  block   ('addrspacecast')
  store   ('_Z13get_global_idj.exit'):   store i32 %8, i32* %.reg2mem5
  reload  ('.lr.ph.i'):   %.reload7 = load i32, i32* %.reg2mem5
  reload  ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.reload6 = load i32, i32* %.reg2mem5

mem2reg:   %.reg2mem8 = alloca i32, !op_varying !19, !res_vector !19, !consecutive !19
  block   ('addrspacecast')
  store   ('.lr.ph.i'):   store i32 %13, i32* %.reg2mem8
  store   ('.lr.ph.i'):   store i32 undef, i32* %.reg2mem8
  reload  ('.lr.ph.i'):   %.reload10 = load i32, i32* %.reg2mem8
  reload  ('.lr.ph.i'):   %.reload9 = load i32, i32* %.reg2mem8

mem2reg:   %.reg2mem11 = alloca float, !op_varying !19, !res_vector !19, !random !19, !unaligned !19
  block   ('addrspacecast')
  store   ('.lr.ph.i'):   store float %24, float* %.reg2mem11
  reload  ('.lr.ph.i..lr.ph.i_crit_edge'):   %.reload13 = load float, float* %.reg2mem11
  reload  ('.lr.ph.i'):   %.reload12 = load float, float* %.reg2mem11

mem2reg:   %.reg2mem14 = alloca i32, !op_uniform !19, !res_uniform !19, !same !19, !unaligned !19
  block   ('addrspacecast')
  store   ('.lr.ph.i'):   store i32 %25, i32* %.reg2mem14
  reload  ('.lr.ph.i..lr.ph.i_crit_edge'):   %.reload16 = load i32, i32* %.reg2mem14
  reload  ('.lr.ph.i'):   %.reload15 = load i32, i32* %.reg2mem14

mem2reg:   %.lcssa1.reg2mem = alloca float, !op_uniform !19, !res_vector !19, !random !19, !unaligned !19
  block   ('addrspacecast')
  store   ('.lr.ph.i'):   store float %24, float* %.lcssa1.reg2mem
  reload  ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.lcssa1.reload = load float, float* %.lcssa1.reg2mem

mem2reg:   %.lcssa.reg2mem = alloca i32, !op_uniform !19, !res_vector !19, !consecutive !19, !unaligned !19
  block   ('addrspacecast')
  store   ('.lr.ph.i'):   store i32 %13, i32* %.lcssa.reg2mem
  reload  ('_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit'):   %.lcssa.reload = load i32, i32* %.lcssa.reg2mem

Linearization of function finished!

define internal ptx_kernel void @"_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE.wfv.tmp"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) #2 {
addrspacecast:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit, !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit:                          ; preds = %addrspacecast
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

.lr.ph.i:                                         ; preds = %.lr.ph.i..lr.ph.i_crit_edge, %_Z13get_global_idj.exit
  %val.0.i = phi float [ 0.000000e+00, %_Z13get_global_idj.exit ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i = phi i32 [ 0, %_Z13get_global_idj.exit ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i, %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i, %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i, 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge, label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge:                      ; preds = %.lr.ph.i
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i, !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit": ; preds = %.lr.ph.i
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %24, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}

#########################################################
## INSTRUCTION VECTORIZATION
#########################################################

creating bitcast to equivalent vector type for argument: float addrspace(1)* %args
  is no vector type - ignored!
creating bitcast to equivalent vector type for argument: float addrspace(1)* %args1
  is no vector type - ignored!
creating bitcast to equivalent vector type for argument: float addrspace(1)* %args2
define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit., !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi float [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i., %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i., 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %24, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}


define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit., !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi float [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load float, float* %20, align 4, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd float %val.0.i., %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i., 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  store float %24, float* %29, align 4, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}


  is no vector type - ignored!

---------------------------------------------------------
| INSERT PACK/UNPACK INTRINSICS
---------------------------------------------------------

after insertPackUnpackIntrinsics:
---------------------------------------------------------
| OPTIMIZE PACK/UNPACK OPERATIONS
---------------------------------------------------------

---------------------------------------------------------
| DUPLICATE SPLIT INSTRUCTIONS
---------------------------------------------------------

after duplicateSplitInstructions:
---------------------------------------------------------
| VECTORIZE INSTRUCTIONS
---------------------------------------------------------
vectorizeInstruction(  %val.0.i. = phi float [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25 )
vectorizeInstruction(  %20 = getelementptr inbounds float, float* %1, i64 %19, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25 )
  GEP can be vectorized!
  inserted new GEP:   %20 = getelementptr float, float* %1, i64 %19, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
vectorizeInstruction(  %22 = load float, <8 x float>* %pktPtrCast, align 4, !op_varying !25, !res_vector !25, !random !25, !unaligned !25 )
  pointer:   %pktPtrCast = bitcast float* %20 to <8 x float>*, !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25, !wfv_pkt_ptr_cast !25
  unaligned vector load required!
LOAD WAS VECTORIZED (UNALIGNED)!
vectorizeInstruction(  %23 = fmul float %21, <8 x float> %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25 )
vectorizeInstruction(  %24 = fadd <8 x float> %val.0.i., %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25 )
vectorizeInstruction(  %29 = getelementptr inbounds float, float* %2, i64 %28, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25 )
  GEP can be vectorized!
  inserted new GEP:   %29 = getelementptr float, float* %2, i64 %28, !op_varying !25, !res_vector !25, !consecutive !25, !unaligned !25
vectorizeInstruction(  store <8 x float> %24, <8 x float>* %pktPtrCast1, align 4, !op_varying !25 )
  pointer:   %pktPtrCast1 = bitcast float* %29 to <8 x float>*, !op_uniform !25, !res_vector !25, !consecutive !25, !unaligned !25, !wfv_pkt_ptr_cast !25
  value:   %24 = fadd <8 x float> %val.0.i., %23, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit., !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi <8 x float> [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast = bitcast float* %20 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load <8 x float>, <8 x float>* %pktPtrCast, align 1, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, <8 x float> %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd <8 x float> %val.0.i., %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i., 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast1 = bitcast float* %29 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  store <8 x float> %24, <8 x float>* %pktPtrCast1, align 1, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}


define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit., !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi <8 x float> [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast = bitcast float* %20 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load <8 x float>, <8 x float>* %pktPtrCast, align 1, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, <8 x float> %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd <8 x float> %val.0.i., %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i., 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast1 = bitcast float* %29 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  store <8 x float> %24, <8 x float>* %pktPtrCast1, align 1, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}


define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit., !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi <8 x float> [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %25, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast = bitcast float* %20 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load <8 x float>, <8 x float>* %pktPtrCast, align 1, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = fmul float %21, <8 x float> %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %24 = fadd <8 x float> %val.0.i., %23, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %25 = add nuw nsw i32 %i.0.i., 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %26 = icmp slt i32 %25, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %26, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %27 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %28 = sext i32 %27 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %29 = getelementptr float, float* %2, i64 %28, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast1 = bitcast float* %29 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  store <8 x float> %24, <8 x float>* %pktPtrCast1, align 1, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}


  block entry mask is FULLY_UNIFORM and pointer is not INDEX_RANDOM -> can use vector store!
  unaligned vector store required!
STORE WAS VECTORIZED (UNALIGNED)!

after vectorizeInstructions:
---------------------------------------------------------
| GENERATE PACK/UNPACK OPERATIONS
---------------------------------------------------------

after generatePackUnpackCode:
---------------------------------------------------------
| GENERATE SIDE-EFFECT GUARDS
---------------------------------------------------------

after generateSideEffectGuards:
---------------------------------------------------------
| BROADCAST UNIFORM OPERANDS
---------------------------------------------------------
broadcastUniformOperands(  %val.0.i. = phi <8 x float> [ 0.000000e+00, %_Z13get_global_idj.exit. ], [ %24, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !25, !res_vector !25, !random !25, !unaligned !25 )
broadcastUniformOperands(  %12 = mul i32 %9, %10, !idx !25, !op_varying !25, !res_vector !25 )
broadcastUniformOperands(  %22 = load <8 x float>, <8 x float>* %pktPtrCast, align 1, !op_varying !25, !res_vector !25, !random !25, !unaligned !25 )
broadcastUniformOperands(  %23 = fmul float %21, <8 x float> %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25 )
    found scalar operand in instruction:   %23 = fmul float %21, <8 x float> %22, !op_varying !25, !res_vector !25, !random !25, !unaligned !25
      broadcasting value:   %21 = load float, float* %16, align 4, !op_uniform !25, !res_uniform !25, !same !25, !unaligned !25
      new value:   %30 = insertelement <8 x float> %29, float %21, i32 7, !wfv_pack_unpack !25
broadcastUniformOperands(  %32 = fadd <8 x float> %val.0.i., %31, !op_varying !25, !res_vector !25, !random !25, !unaligned !25 )
broadcastUniformOperands(  store <8 x float> %32, <8 x float>* %pktPtrCast1, align 1, !op_varying !25
define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  tail call void @wfvMetadataFn() #3, !wfv_arg_info !21, !always_by_all !27, !optional !27, !non_divergent !27
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  br label %_Z13get_global_idj.exit., !op_uniform !27, !res_uniform !27

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !27, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %6 = mul i32 %3, %4, !idy !27, !op_uniform !27, !res_uniform !27
  %7 = add i32 %6, %5, !global_id_y !27, !op_uniform !27, !res_uniform !27, !same !27
  %8 = mul nsw i32 %7, 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi <8 x float> [ zeroinitializer, %_Z13get_global_idj.exit. ], [ %32, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_vector !27, !random !27, !unaligned !27
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %33, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  tail call void @wfvMetadataFn() #3, !loop_non_divergent !27, !always_by_all !27, !optional !27, !non_divergent !27
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !27, !op_sequential !27, !res_vector !27, !random !27, !unaligned !27
  %12 = mul i32 %9, %10, !idx !27, !op_varying !27, !res_vector !27
  %13 = add i32 %12, %11, !global_id_x !27, !op_varying !27, !res_vector !27, !consecutive !27
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %15 = sext i32 %14 to i64, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !27, !res_uniform !27, !same !27, !aligned !27
  %18 = add nsw i32 %17, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %19 = sext i32 %18 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %20 = getelementptr float, float* %1, i64 %19, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast = bitcast float* %20 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  %21 = load float, float* %16, align 4, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %22 = load <8 x float>, <8 x float>* %pktPtrCast, align 1, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %23 = insertelement <8 x float> undef, float %21, i32 0, !wfv_pack_unpack !27
  %24 = insertelement <8 x float> %23, float %21, i32 1, !wfv_pack_unpack !27
  %25 = insertelement <8 x float> %24, float %21, i32 2, !wfv_pack_unpack !27
  %26 = insertelement <8 x float> %25, float %21, i32 3, !wfv_pack_unpack !27
  %27 = insertelement <8 x float> %26, float %21, i32 4, !wfv_pack_unpack !27
  %28 = insertelement <8 x float> %27, float %21, i32 5, !wfv_pack_unpack !27
  %29 = insertelement <8 x float> %28, float %21, i32 6, !wfv_pack_unpack !27
  %30 = insertelement <8 x float> %29, float %21, i32 7, !wfv_pack_unpack !27
  %31 = fmul <8 x float> %30, %22, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %32 = fadd <8 x float> %val.0.i., %31, !op_varying !27, !res_vector !27, !random !27, !unaligned !27
  %33 = add nuw nsw i32 %i.0.i., 1, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27
  %34 = icmp slt i32 %33, 1024, !op_uniform !27, !res_uniform !27, !same !27, !unaligned !27, !mask !27
  br i1 %34, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !27, !res_uniform !27

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all_or_none !27, !optional !27, !non_divergent !27
  br label %.lr.ph.i., !op_uniform !27, !res_uniform !27

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  tail call void @wfvMetadataFn() #3, !always_by_all !27, !optional !27, !non_divergent !27
  %35 = add nsw i32 %8, %13, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %36 = sext i32 %35 to i64, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %37 = getelementptr float, float* %2, i64 %36, !op_varying !27, !res_vector !27, !consecutive !27, !unaligned !27
  %pktPtrCast1 = bitcast float* %37 to <8 x float>*, !op_uniform !27, !res_vector !27, !consecutive !27, !unaligned !27, !wfv_pkt_ptr_cast !27
  store <8 x float> %32, <8 x float>* %pktPtrCast1, align 1, !op_varying !27
  ret void, !op_uniform !27, !res_uniform !27
}

 )

after broadcastUniformOperands:Cleaning up function after WFV... done.

after cleanup:
define void @"__vectorized___ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE"(i8 %callable.coerce, float addrspace(1)* %args, float addrspace(1)* %args1, float addrspace(1)* %args2, i32 %args3) {
addrspacecast.:
  %0 = addrspacecast float addrspace(1)* %args to float*, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %1 = addrspacecast float addrspace(1)* %args1 to float*, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %2 = addrspacecast float addrspace(1)* %args2 to float*, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  br label %_Z13get_global_idj.exit., !op_uniform !21, !res_uniform !21

_Z13get_global_idj.exit.:                         ; preds = %addrspacecast.
  %3 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.y() #4, !idy !21, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %4 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.y() #4, !idy !21, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %5 = call i32 @llvm.nvvm.read.ptx.sreg.tid.y() #4, !idy !21, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %6 = mul i32 %3, %4, !idy !21, !op_uniform !21, !res_uniform !21
  %7 = add i32 %6, %5, !global_id_y !21, !op_uniform !21, !res_uniform !21, !same !21
  %8 = mul nsw i32 %7, 1024, !op_uniform !21, !res_uniform !21, !same !21, !aligned !21
  br label %.lr.ph.i., !op_uniform !21, !res_uniform !21

.lr.ph.i.:                                        ; preds = %.lr.ph.i..lr.ph.i_crit_edge., %_Z13get_global_idj.exit.
  %val.0.i. = phi <8 x float> [ zeroinitializer, %_Z13get_global_idj.exit. ], [ %32, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !21, !res_vector !21, !random !21, !unaligned !21
  %i.0.i. = phi i32 [ 0, %_Z13get_global_idj.exit. ], [ %33, %.lr.ph.i..lr.ph.i_crit_edge. ], !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %9 = call i32 @llvm.nvvm.read.ptx.sreg.ntid.x() #4, !idx !21, !op_sequential !21, !res_vector !21, !random !21, !unaligned !21
  %10 = call i32 @llvm.nvvm.read.ptx.sreg.ctaid.x() #4, !idx !21, !op_sequential !21, !res_vector !21, !random !21, !unaligned !21
  %11 = call i32 @llvm.nvvm.read.ptx.sreg.tid.x() #4, !idx !21, !op_sequential !21, !res_vector !21, !random !21, !unaligned !21
  %12 = mul i32 %9, %10, !idx !21, !op_varying !21, !res_vector !21
  %13 = add i32 %12, %11, !global_id_x !21, !op_varying !21, !res_vector !21, !consecutive !21
  %14 = add nsw i32 %i.0.i., %8, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %15 = sext i32 %14 to i64, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %16 = getelementptr inbounds float, float* %0, i64 %15, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %17 = mul nsw i32 %i.0.i., 1024, !op_uniform !21, !res_uniform !21, !same !21, !aligned !21
  %18 = add nsw i32 %17, %13, !op_varying !21, !res_vector !21, !consecutive !21, !unaligned !21
  %19 = sext i32 %18 to i64, !op_varying !21, !res_vector !21, !consecutive !21, !unaligned !21
  %20 = getelementptr float, float* %1, i64 %19, !op_varying !21, !res_vector !21, !consecutive !21, !unaligned !21
  %pktPtrCast = bitcast float* %20 to <8 x float>*, !op_uniform !21, !res_vector !21, !consecutive !21, !unaligned !21, !wfv_pkt_ptr_cast !21
  %21 = load float, float* %16, align 4, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %22 = load <8 x float>, <8 x float>* %pktPtrCast, align 1, !op_varying !21, !res_vector !21, !random !21, !unaligned !21
  %23 = insertelement <8 x float> undef, float %21, i32 0, !wfv_pack_unpack !21
  %24 = insertelement <8 x float> %23, float %21, i32 1, !wfv_pack_unpack !21
  %25 = insertelement <8 x float> %24, float %21, i32 2, !wfv_pack_unpack !21
  %26 = insertelement <8 x float> %25, float %21, i32 3, !wfv_pack_unpack !21
  %27 = insertelement <8 x float> %26, float %21, i32 4, !wfv_pack_unpack !21
  %28 = insertelement <8 x float> %27, float %21, i32 5, !wfv_pack_unpack !21
  %29 = insertelement <8 x float> %28, float %21, i32 6, !wfv_pack_unpack !21
  %30 = insertelement <8 x float> %29, float %21, i32 7, !wfv_pack_unpack !21
  %31 = fmul <8 x float> %30, %22, !op_varying !21, !res_vector !21, !random !21, !unaligned !21
  %32 = fadd <8 x float> %val.0.i., %31, !op_varying !21, !res_vector !21, !random !21, !unaligned !21
  %33 = add nuw nsw i32 %i.0.i., 1, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21
  %34 = icmp slt i32 %33, 1024, !op_uniform !21, !res_uniform !21, !same !21, !unaligned !21, !mask !21
  br i1 %34, label %.lr.ph.i..lr.ph.i_crit_edge., label %"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.", !op_uniform !21, !res_uniform !21

.lr.ph.i..lr.ph.i_crit_edge.:                     ; preds = %.lr.ph.i.
  br label %.lr.ph.i., !op_uniform !21, !res_uniform !21

"_ZZ10calcNativePfS_S_mENK12$_3586529055clEPKfS2_S_i.exit.": ; preds = %.lr.ph.i.
  %35 = add nsw i32 %8, %13, !op_varying !21, !res_vector !21, !consecutive !21, !unaligned !21
  %36 = sext i32 %35 to i64, !op_varying !21, !res_vector !21, !consecutive !21, !unaligned !21
  %37 = getelementptr float, float* %2, i64 %36, !op_varying !21, !res_vector !21, !consecutive !21, !unaligned !21
  %pktPtrCast1 = bitcast float* %37 to <8 x float>*, !op_uniform !21, !res_vector !21, !consecutive !21, !unaligned !21, !wfv_pkt_ptr_cast !21
  store <8 x float> %32, <8 x float>* %pktPtrCast1, align 1, !op_varying !21
  ret void, !op_uniform !21, !res_uniform !21
}
===-------------------------------------------------------------------------===
                          Whole-Function Vectorization
===-------------------------------------------------------------------------===
  Total Execution Time: 0.0160 seconds (0.0173 wall clock)

   --System Time--   --User+System--   ---Wall Time---  --- Name ---
   0.0160 (100.0%)   0.0160 (100.0%)   0.0173 (100.0%)  Function Vectorizer
   0.0160 (100.0%)   0.0160 (100.0%)   0.0173 (100.0%)  Total

timed (pacxx): 211844us
timed (seq): 1713608us
1
### Whole-Function Vectorization of function '_ZN5pacxx2v213genericKernelILm0EZ10calcNativePfS2_S2_mE12$_3586529055JS2_S2_S2_iEEEvT0_DpNSt3__111conditionalIXsr3std12is_referenceIT1_EE5valueENS5_20add_lvalue_referenceINS0_17generic_to_globalIS7_E4typeEE4typeESB_E4typeE' SUCCESSFUL!
